{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28367f9-37a5-40a0-ba3c-64c0750d1f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B.NIKITHA\n",
    "#230701211\n",
    "#CSE-D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('Social_Network_Ads.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8513af-1605-4344-b4b9-356dcfe74caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df.iloc[:,[2,3]].values\n",
    "label=df.iloc[:,4].values\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889b644d-3bb5-4aff-8ca0-757cf53be061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32c9ed9-a15c-4489-b002-642851c377d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.725 Train0.621875 Random State 1\n",
      "Test 0.725 Train0.621875 Random State 2\n",
      "Test 0.725 Train0.621875 Random State 3\n",
      "Test 0.725 Train0.621875 Random State 4\n",
      "Test 0.725 Train0.621875 Random State 5\n",
      "Test 0.725 Train0.621875 Random State 6\n",
      "Test 0.725 Train0.621875 Random State 7\n",
      "Test 0.725 Train0.621875 Random State 8\n",
      "Test 0.725 Train0.621875 Random State 9\n",
      "Test 0.725 Train0.621875 Random State 10\n",
      "Test 0.725 Train0.621875 Random State 11\n",
      "Test 0.725 Train0.621875 Random State 12\n",
      "Test 0.725 Train0.621875 Random State 13\n",
      "Test 0.725 Train0.621875 Random State 14\n",
      "Test 0.725 Train0.621875 Random State 15\n",
      "Test 0.725 Train0.621875 Random State 16\n",
      "Test 0.725 Train0.621875 Random State 17\n",
      "Test 0.725 Train0.621875 Random State 18\n",
      "Test 0.725 Train0.621875 Random State 19\n",
      "Test 0.725 Train0.621875 Random State 20\n",
      "Test 0.725 Train0.621875 Random State 21\n",
      "Test 0.725 Train0.621875 Random State 22\n",
      "Test 0.725 Train0.621875 Random State 23\n",
      "Test 0.725 Train0.621875 Random State 24\n",
      "Test 0.725 Train0.621875 Random State 25\n",
      "Test 0.725 Train0.621875 Random State 26\n",
      "Test 0.725 Train0.621875 Random State 27\n",
      "Test 0.725 Train0.621875 Random State 28\n",
      "Test 0.725 Train0.621875 Random State 29\n",
      "Test 0.725 Train0.621875 Random State 30\n",
      "Test 0.725 Train0.621875 Random State 31\n",
      "Test 0.725 Train0.621875 Random State 32\n",
      "Test 0.725 Train0.621875 Random State 33\n",
      "Test 0.725 Train0.621875 Random State 34\n",
      "Test 0.725 Train0.621875 Random State 35\n",
      "Test 0.725 Train0.621875 Random State 36\n",
      "Test 0.725 Train0.621875 Random State 37\n",
      "Test 0.725 Train0.621875 Random State 38\n",
      "Test 0.725 Train0.621875 Random State 39\n",
      "Test 0.725 Train0.621875 Random State 40\n",
      "Test 0.725 Train0.621875 Random State 41\n",
      "Test 0.725 Train0.621875 Random State 42\n",
      "Test 0.725 Train0.621875 Random State 43\n",
      "Test 0.725 Train0.621875 Random State 44\n",
      "Test 0.725 Train0.621875 Random State 45\n",
      "Test 0.725 Train0.621875 Random State 46\n",
      "Test 0.725 Train0.621875 Random State 47\n",
      "Test 0.725 Train0.621875 Random State 48\n",
      "Test 0.725 Train0.621875 Random State 49\n",
      "Test 0.725 Train0.621875 Random State 50\n",
      "Test 0.725 Train0.621875 Random State 51\n",
      "Test 0.725 Train0.621875 Random State 52\n",
      "Test 0.725 Train0.621875 Random State 53\n",
      "Test 0.725 Train0.621875 Random State 54\n",
      "Test 0.725 Train0.621875 Random State 55\n",
      "Test 0.725 Train0.621875 Random State 56\n",
      "Test 0.725 Train0.621875 Random State 57\n",
      "Test 0.725 Train0.621875 Random State 58\n",
      "Test 0.725 Train0.621875 Random State 59\n",
      "Test 0.725 Train0.621875 Random State 60\n",
      "Test 0.725 Train0.621875 Random State 61\n",
      "Test 0.725 Train0.621875 Random State 62\n",
      "Test 0.725 Train0.621875 Random State 63\n",
      "Test 0.725 Train0.621875 Random State 64\n",
      "Test 0.725 Train0.621875 Random State 65\n",
      "Test 0.725 Train0.621875 Random State 66\n",
      "Test 0.725 Train0.621875 Random State 67\n",
      "Test 0.725 Train0.621875 Random State 68\n",
      "Test 0.725 Train0.621875 Random State 69\n",
      "Test 0.725 Train0.621875 Random State 70\n",
      "Test 0.725 Train0.621875 Random State 71\n",
      "Test 0.725 Train0.621875 Random State 72\n",
      "Test 0.725 Train0.621875 Random State 73\n",
      "Test 0.725 Train0.621875 Random State 74\n",
      "Test 0.725 Train0.621875 Random State 75\n",
      "Test 0.725 Train0.621875 Random State 76\n",
      "Test 0.725 Train0.621875 Random State 77\n",
      "Test 0.725 Train0.621875 Random State 78\n",
      "Test 0.725 Train0.621875 Random State 79\n",
      "Test 0.725 Train0.621875 Random State 80\n",
      "Test 0.725 Train0.621875 Random State 81\n",
      "Test 0.725 Train0.621875 Random State 82\n",
      "Test 0.725 Train0.621875 Random State 83\n",
      "Test 0.725 Train0.621875 Random State 84\n",
      "Test 0.725 Train0.621875 Random State 85\n",
      "Test 0.725 Train0.621875 Random State 86\n",
      "Test 0.725 Train0.621875 Random State 87\n",
      "Test 0.725 Train0.621875 Random State 88\n",
      "Test 0.725 Train0.621875 Random State 89\n",
      "Test 0.725 Train0.621875 Random State 90\n",
      "Test 0.725 Train0.621875 Random State 91\n",
      "Test 0.725 Train0.621875 Random State 92\n",
      "Test 0.725 Train0.621875 Random State 93\n",
      "Test 0.725 Train0.621875 Random State 94\n",
      "Test 0.725 Train0.621875 Random State 95\n",
      "Test 0.725 Train0.621875 Random State 96\n",
      "Test 0.725 Train0.621875 Random State 97\n",
      "Test 0.725 Train0.621875 Random State 98\n",
      "Test 0.725 Train0.621875 Random State 99\n",
      "Test 0.725 Train0.621875 Random State 100\n",
      "Test 0.725 Train0.621875 Random State 101\n",
      "Test 0.725 Train0.621875 Random State 102\n",
      "Test 0.725 Train0.621875 Random State 103\n",
      "Test 0.725 Train0.621875 Random State 104\n",
      "Test 0.725 Train0.621875 Random State 105\n",
      "Test 0.725 Train0.621875 Random State 106\n",
      "Test 0.725 Train0.621875 Random State 107\n",
      "Test 0.725 Train0.621875 Random State 108\n",
      "Test 0.725 Train0.621875 Random State 109\n",
      "Test 0.725 Train0.621875 Random State 110\n",
      "Test 0.725 Train0.621875 Random State 111\n",
      "Test 0.725 Train0.621875 Random State 112\n",
      "Test 0.725 Train0.621875 Random State 113\n",
      "Test 0.725 Train0.621875 Random State 114\n",
      "Test 0.725 Train0.621875 Random State 115\n",
      "Test 0.725 Train0.621875 Random State 116\n",
      "Test 0.725 Train0.621875 Random State 117\n",
      "Test 0.725 Train0.621875 Random State 118\n",
      "Test 0.725 Train0.621875 Random State 119\n",
      "Test 0.725 Train0.621875 Random State 120\n",
      "Test 0.725 Train0.621875 Random State 121\n",
      "Test 0.725 Train0.621875 Random State 122\n",
      "Test 0.725 Train0.621875 Random State 123\n",
      "Test 0.725 Train0.621875 Random State 124\n",
      "Test 0.725 Train0.621875 Random State 125\n",
      "Test 0.725 Train0.621875 Random State 126\n",
      "Test 0.725 Train0.621875 Random State 127\n",
      "Test 0.725 Train0.621875 Random State 128\n",
      "Test 0.725 Train0.621875 Random State 129\n",
      "Test 0.725 Train0.621875 Random State 130\n",
      "Test 0.725 Train0.621875 Random State 131\n",
      "Test 0.725 Train0.621875 Random State 132\n",
      "Test 0.725 Train0.621875 Random State 133\n",
      "Test 0.725 Train0.621875 Random State 134\n",
      "Test 0.725 Train0.621875 Random State 135\n",
      "Test 0.725 Train0.621875 Random State 136\n",
      "Test 0.725 Train0.621875 Random State 137\n",
      "Test 0.725 Train0.621875 Random State 138\n",
      "Test 0.725 Train0.621875 Random State 139\n",
      "Test 0.725 Train0.621875 Random State 140\n",
      "Test 0.725 Train0.621875 Random State 141\n",
      "Test 0.725 Train0.621875 Random State 142\n",
      "Test 0.725 Train0.621875 Random State 143\n",
      "Test 0.725 Train0.621875 Random State 144\n",
      "Test 0.725 Train0.621875 Random State 145\n",
      "Test 0.725 Train0.621875 Random State 146\n",
      "Test 0.725 Train0.621875 Random State 147\n",
      "Test 0.725 Train0.621875 Random State 148\n",
      "Test 0.725 Train0.621875 Random State 149\n",
      "Test 0.725 Train0.621875 Random State 150\n",
      "Test 0.725 Train0.621875 Random State 151\n",
      "Test 0.725 Train0.621875 Random State 152\n",
      "Test 0.725 Train0.621875 Random State 153\n",
      "Test 0.725 Train0.621875 Random State 154\n",
      "Test 0.725 Train0.621875 Random State 155\n",
      "Test 0.725 Train0.621875 Random State 156\n",
      "Test 0.725 Train0.621875 Random State 157\n",
      "Test 0.725 Train0.621875 Random State 158\n",
      "Test 0.725 Train0.621875 Random State 159\n",
      "Test 0.725 Train0.621875 Random State 160\n",
      "Test 0.725 Train0.621875 Random State 161\n",
      "Test 0.725 Train0.621875 Random State 162\n",
      "Test 0.725 Train0.621875 Random State 163\n",
      "Test 0.725 Train0.621875 Random State 164\n",
      "Test 0.725 Train0.621875 Random State 165\n",
      "Test 0.725 Train0.621875 Random State 166\n",
      "Test 0.725 Train0.621875 Random State 167\n",
      "Test 0.725 Train0.621875 Random State 168\n",
      "Test 0.725 Train0.621875 Random State 169\n",
      "Test 0.725 Train0.621875 Random State 170\n",
      "Test 0.725 Train0.621875 Random State 171\n",
      "Test 0.725 Train0.621875 Random State 172\n",
      "Test 0.725 Train0.621875 Random State 173\n",
      "Test 0.725 Train0.621875 Random State 174\n",
      "Test 0.725 Train0.621875 Random State 175\n",
      "Test 0.725 Train0.621875 Random State 176\n",
      "Test 0.725 Train0.621875 Random State 177\n",
      "Test 0.725 Train0.621875 Random State 178\n",
      "Test 0.725 Train0.621875 Random State 179\n",
      "Test 0.725 Train0.621875 Random State 180\n",
      "Test 0.725 Train0.621875 Random State 181\n",
      "Test 0.725 Train0.621875 Random State 182\n",
      "Test 0.725 Train0.621875 Random State 183\n",
      "Test 0.725 Train0.621875 Random State 184\n",
      "Test 0.725 Train0.621875 Random State 185\n",
      "Test 0.725 Train0.621875 Random State 186\n",
      "Test 0.725 Train0.621875 Random State 187\n",
      "Test 0.725 Train0.621875 Random State 188\n",
      "Test 0.725 Train0.621875 Random State 189\n",
      "Test 0.725 Train0.621875 Random State 190\n",
      "Test 0.725 Train0.621875 Random State 191\n",
      "Test 0.725 Train0.621875 Random State 192\n",
      "Test 0.725 Train0.621875 Random State 193\n",
      "Test 0.725 Train0.621875 Random State 194\n",
      "Test 0.725 Train0.621875 Random State 195\n",
      "Test 0.725 Train0.621875 Random State 196\n",
      "Test 0.725 Train0.621875 Random State 197\n",
      "Test 0.725 Train0.621875 Random State 198\n",
      "Test 0.725 Train0.621875 Random State 199\n",
      "Test 0.725 Train0.621875 Random State 200\n",
      "Test 0.725 Train0.621875 Random State 201\n",
      "Test 0.725 Train0.621875 Random State 202\n",
      "Test 0.725 Train0.621875 Random State 203\n",
      "Test 0.725 Train0.621875 Random State 204\n",
      "Test 0.725 Train0.621875 Random State 205\n",
      "Test 0.725 Train0.621875 Random State 206\n",
      "Test 0.725 Train0.621875 Random State 207\n",
      "Test 0.725 Train0.621875 Random State 208\n",
      "Test 0.725 Train0.621875 Random State 209\n",
      "Test 0.725 Train0.621875 Random State 210\n",
      "Test 0.725 Train0.621875 Random State 211\n",
      "Test 0.725 Train0.621875 Random State 212\n",
      "Test 0.725 Train0.621875 Random State 213\n",
      "Test 0.725 Train0.621875 Random State 214\n",
      "Test 0.725 Train0.621875 Random State 215\n",
      "Test 0.725 Train0.621875 Random State 216\n",
      "Test 0.725 Train0.621875 Random State 217\n",
      "Test 0.725 Train0.621875 Random State 218\n",
      "Test 0.725 Train0.621875 Random State 219\n",
      "Test 0.725 Train0.621875 Random State 220\n",
      "Test 0.725 Train0.621875 Random State 221\n",
      "Test 0.725 Train0.621875 Random State 222\n",
      "Test 0.725 Train0.621875 Random State 223\n",
      "Test 0.725 Train0.621875 Random State 224\n",
      "Test 0.725 Train0.621875 Random State 225\n",
      "Test 0.725 Train0.621875 Random State 226\n",
      "Test 0.725 Train0.621875 Random State 227\n",
      "Test 0.725 Train0.621875 Random State 228\n",
      "Test 0.725 Train0.621875 Random State 229\n",
      "Test 0.725 Train0.621875 Random State 230\n",
      "Test 0.725 Train0.621875 Random State 231\n",
      "Test 0.725 Train0.621875 Random State 232\n",
      "Test 0.725 Train0.621875 Random State 233\n",
      "Test 0.725 Train0.621875 Random State 234\n",
      "Test 0.725 Train0.621875 Random State 235\n",
      "Test 0.725 Train0.621875 Random State 236\n",
      "Test 0.725 Train0.621875 Random State 237\n",
      "Test 0.725 Train0.621875 Random State 238\n",
      "Test 0.725 Train0.621875 Random State 239\n",
      "Test 0.725 Train0.621875 Random State 240\n",
      "Test 0.725 Train0.621875 Random State 241\n",
      "Test 0.725 Train0.621875 Random State 242\n",
      "Test 0.725 Train0.621875 Random State 243\n",
      "Test 0.725 Train0.621875 Random State 244\n",
      "Test 0.725 Train0.621875 Random State 245\n",
      "Test 0.725 Train0.621875 Random State 246\n",
      "Test 0.725 Train0.621875 Random State 247\n",
      "Test 0.725 Train0.621875 Random State 248\n",
      "Test 0.725 Train0.621875 Random State 249\n",
      "Test 0.725 Train0.621875 Random State 250\n",
      "Test 0.725 Train0.621875 Random State 251\n",
      "Test 0.725 Train0.621875 Random State 252\n",
      "Test 0.725 Train0.621875 Random State 253\n",
      "Test 0.725 Train0.621875 Random State 254\n",
      "Test 0.725 Train0.621875 Random State 255\n",
      "Test 0.725 Train0.621875 Random State 256\n",
      "Test 0.725 Train0.621875 Random State 257\n",
      "Test 0.725 Train0.621875 Random State 258\n",
      "Test 0.725 Train0.621875 Random State 259\n",
      "Test 0.725 Train0.621875 Random State 260\n",
      "Test 0.725 Train0.621875 Random State 261\n",
      "Test 0.725 Train0.621875 Random State 262\n",
      "Test 0.725 Train0.621875 Random State 263\n",
      "Test 0.725 Train0.621875 Random State 264\n",
      "Test 0.725 Train0.621875 Random State 265\n",
      "Test 0.725 Train0.621875 Random State 266\n",
      "Test 0.725 Train0.621875 Random State 267\n",
      "Test 0.725 Train0.621875 Random State 268\n",
      "Test 0.725 Train0.621875 Random State 269\n",
      "Test 0.725 Train0.621875 Random State 270\n",
      "Test 0.725 Train0.621875 Random State 271\n",
      "Test 0.725 Train0.621875 Random State 272\n",
      "Test 0.725 Train0.621875 Random State 273\n",
      "Test 0.725 Train0.621875 Random State 274\n",
      "Test 0.725 Train0.621875 Random State 275\n",
      "Test 0.725 Train0.621875 Random State 276\n",
      "Test 0.725 Train0.621875 Random State 277\n",
      "Test 0.725 Train0.621875 Random State 278\n",
      "Test 0.725 Train0.621875 Random State 279\n",
      "Test 0.725 Train0.621875 Random State 280\n",
      "Test 0.725 Train0.621875 Random State 281\n",
      "Test 0.725 Train0.621875 Random State 282\n",
      "Test 0.725 Train0.621875 Random State 283\n",
      "Test 0.725 Train0.621875 Random State 284\n",
      "Test 0.725 Train0.621875 Random State 285\n",
      "Test 0.725 Train0.621875 Random State 286\n",
      "Test 0.725 Train0.621875 Random State 287\n",
      "Test 0.725 Train0.621875 Random State 288\n",
      "Test 0.725 Train0.621875 Random State 289\n",
      "Test 0.725 Train0.621875 Random State 290\n",
      "Test 0.725 Train0.621875 Random State 291\n",
      "Test 0.725 Train0.621875 Random State 292\n",
      "Test 0.725 Train0.621875 Random State 293\n",
      "Test 0.725 Train0.621875 Random State 294\n",
      "Test 0.725 Train0.621875 Random State 295\n",
      "Test 0.725 Train0.621875 Random State 296\n",
      "Test 0.725 Train0.621875 Random State 297\n",
      "Test 0.725 Train0.621875 Random State 298\n",
      "Test 0.725 Train0.621875 Random State 299\n",
      "Test 0.725 Train0.621875 Random State 300\n",
      "Test 0.725 Train0.621875 Random State 301\n",
      "Test 0.725 Train0.621875 Random State 302\n",
      "Test 0.725 Train0.621875 Random State 303\n",
      "Test 0.725 Train0.621875 Random State 304\n",
      "Test 0.725 Train0.621875 Random State 305\n",
      "Test 0.725 Train0.621875 Random State 306\n",
      "Test 0.725 Train0.621875 Random State 307\n",
      "Test 0.725 Train0.621875 Random State 308\n",
      "Test 0.725 Train0.621875 Random State 309\n",
      "Test 0.725 Train0.621875 Random State 310\n",
      "Test 0.725 Train0.621875 Random State 311\n",
      "Test 0.725 Train0.621875 Random State 312\n",
      "Test 0.725 Train0.621875 Random State 313\n",
      "Test 0.725 Train0.621875 Random State 314\n",
      "Test 0.725 Train0.621875 Random State 315\n",
      "Test 0.725 Train0.621875 Random State 316\n",
      "Test 0.725 Train0.621875 Random State 317\n",
      "Test 0.725 Train0.621875 Random State 318\n",
      "Test 0.725 Train0.621875 Random State 319\n",
      "Test 0.725 Train0.621875 Random State 320\n",
      "Test 0.725 Train0.621875 Random State 321\n",
      "Test 0.725 Train0.621875 Random State 322\n",
      "Test 0.725 Train0.621875 Random State 323\n",
      "Test 0.725 Train0.621875 Random State 324\n",
      "Test 0.725 Train0.621875 Random State 325\n",
      "Test 0.725 Train0.621875 Random State 326\n",
      "Test 0.725 Train0.621875 Random State 327\n",
      "Test 0.725 Train0.621875 Random State 328\n",
      "Test 0.725 Train0.621875 Random State 329\n",
      "Test 0.725 Train0.621875 Random State 330\n",
      "Test 0.725 Train0.621875 Random State 331\n",
      "Test 0.725 Train0.621875 Random State 332\n",
      "Test 0.725 Train0.621875 Random State 333\n",
      "Test 0.725 Train0.621875 Random State 334\n",
      "Test 0.725 Train0.621875 Random State 335\n",
      "Test 0.725 Train0.621875 Random State 336\n",
      "Test 0.725 Train0.621875 Random State 337\n",
      "Test 0.725 Train0.621875 Random State 338\n",
      "Test 0.725 Train0.621875 Random State 339\n",
      "Test 0.725 Train0.621875 Random State 340\n",
      "Test 0.725 Train0.621875 Random State 341\n",
      "Test 0.725 Train0.621875 Random State 342\n",
      "Test 0.725 Train0.621875 Random State 343\n",
      "Test 0.725 Train0.621875 Random State 344\n",
      "Test 0.725 Train0.621875 Random State 345\n",
      "Test 0.725 Train0.621875 Random State 346\n",
      "Test 0.725 Train0.621875 Random State 347\n",
      "Test 0.725 Train0.621875 Random State 348\n",
      "Test 0.725 Train0.621875 Random State 349\n",
      "Test 0.725 Train0.621875 Random State 350\n",
      "Test 0.725 Train0.621875 Random State 351\n",
      "Test 0.725 Train0.621875 Random State 352\n",
      "Test 0.725 Train0.621875 Random State 353\n",
      "Test 0.725 Train0.621875 Random State 354\n",
      "Test 0.725 Train0.621875 Random State 355\n",
      "Test 0.725 Train0.621875 Random State 356\n",
      "Test 0.725 Train0.621875 Random State 357\n",
      "Test 0.725 Train0.621875 Random State 358\n",
      "Test 0.725 Train0.621875 Random State 359\n",
      "Test 0.725 Train0.621875 Random State 360\n",
      "Test 0.725 Train0.621875 Random State 361\n",
      "Test 0.725 Train0.621875 Random State 362\n",
      "Test 0.725 Train0.621875 Random State 363\n",
      "Test 0.725 Train0.621875 Random State 364\n",
      "Test 0.725 Train0.621875 Random State 365\n",
      "Test 0.725 Train0.621875 Random State 366\n",
      "Test 0.725 Train0.621875 Random State 367\n",
      "Test 0.725 Train0.621875 Random State 368\n",
      "Test 0.725 Train0.621875 Random State 369\n",
      "Test 0.725 Train0.621875 Random State 370\n",
      "Test 0.725 Train0.621875 Random State 371\n",
      "Test 0.725 Train0.621875 Random State 372\n",
      "Test 0.725 Train0.621875 Random State 373\n",
      "Test 0.725 Train0.621875 Random State 374\n",
      "Test 0.725 Train0.621875 Random State 375\n",
      "Test 0.725 Train0.621875 Random State 376\n",
      "Test 0.725 Train0.621875 Random State 377\n",
      "Test 0.725 Train0.621875 Random State 378\n",
      "Test 0.725 Train0.621875 Random State 379\n",
      "Test 0.725 Train0.621875 Random State 380\n",
      "Test 0.725 Train0.621875 Random State 381\n",
      "Test 0.725 Train0.621875 Random State 382\n",
      "Test 0.725 Train0.621875 Random State 383\n",
      "Test 0.725 Train0.621875 Random State 384\n",
      "Test 0.725 Train0.621875 Random State 385\n",
      "Test 0.725 Train0.621875 Random State 386\n",
      "Test 0.725 Train0.621875 Random State 387\n",
      "Test 0.725 Train0.621875 Random State 388\n",
      "Test 0.725 Train0.621875 Random State 389\n",
      "Test 0.725 Train0.621875 Random State 390\n",
      "Test 0.725 Train0.621875 Random State 391\n",
      "Test 0.725 Train0.621875 Random State 392\n",
      "Test 0.725 Train0.621875 Random State 393\n",
      "Test 0.725 Train0.621875 Random State 394\n",
      "Test 0.725 Train0.621875 Random State 395\n",
      "Test 0.725 Train0.621875 Random State 396\n",
      "Test 0.725 Train0.621875 Random State 397\n",
      "Test 0.725 Train0.621875 Random State 398\n",
      "Test 0.725 Train0.621875 Random State 399\n",
      "Test 0.725 Train0.621875 Random State 400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(1,401):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.2,random_state=0)\n",
    "    model=LogisticRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "    train_score=model.score(x_train,y_train)\n",
    "    test_score=model.score(x_test,y_test)\n",
    "    if test_score>train_score:\n",
    "        print(\"Test {} Train{} Random State {}\".format(test_score,train_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a1842b-edcc-443e-9163-bf5378d8e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.2,random_state=0)\n",
    "finalModel=LogisticRegression()\n",
    "finalModel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b710d90-87df-4ff2-bad9-8ad60411833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621875\n",
      "0.725\n"
     ]
    }
   ],
   "source": [
    "print(finalModel.score(x_train,y_train))\n",
    "print(finalModel.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3648355-bde7-4b55-b730-3f447e43e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78       257\n",
      "           1       0.00      0.00      0.00       143\n",
      "\n",
      "    accuracy                           0.64       400\n",
      "   macro avg       0.32      0.50      0.39       400\n",
      "weighted avg       0.41      0.64      0.50       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gvmani\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gvmani\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gvmani\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label,finalModel.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405eb11f-bf2e-49bc-a08a-f3192c25a50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
